_target_: src.models.vcc_lightning.VCCModule
net:
  _target_: src.models.components.vcc_model_attention.CellModelAttention
  ko_processor_args:
    input_size: 512
    hidden_layers: [512,512,512]
    output_size: 256
    dropout: 0.0
    activation: relu
    # no_processing: true
  exp_processor_args:
    input_size: 18080
    hidden_layers: [512,512,512]
    output_size: 256
    dropout: 0.0
    activation: relu
    # no_processing: true
  attention_args:
    embed_dim: 256 # Must be same as the dimensions of your key and value
    num_heads: 4
  decoder_args:
    input_size: 256
    hidden_layers: [512,1024,2048]
    output_size: ${model.net.exp_processor_args.input_size}
    dropout: 0.0
    activation: relu
    residual_connection: false
  fusion_type: 'cross_attn'
loss_fn:
  _target_: torch.nn.MSELoss
optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 5e-4
  weight_decay: 1e-5
scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  _partial_: true
  T_0: 10

# lr: 1e-5
# max_lr: 1e-2
# weight_decay: 1e-5
# composite_loss_lambda: 1
